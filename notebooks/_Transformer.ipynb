{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqyFtHB2Dl1f",
        "outputId": "ccf3f728-5d09-4c27-d2b0-d3c2a14a40cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hilbertcurve in /usr/local/lib/python3.11/dist-packages (2.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hilbertcurve) (2.0.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cuda\n",
            "Experiment directory set to:  /content/drive/MyDrive/BRACS/experiments/spiral/1-30.04-18:40-2d-6head4layer-70epoch-drop20-focalLoss\n",
            "ORDER METHOD spiral\n",
            "=== Train Set Label Distribution ===\n",
            "Benign (Label 0): 202\n",
            "Atypical (Label 1): 52\n",
            "Malignant (Label 2): 140\n",
            "\n",
            "\n",
            "=== Validation Set Label Distribution ===\n",
            "Benign (Label 0): 30\n",
            "Atypical (Label 1): 14\n",
            "Malignant (Label 2): 21\n",
            "\n",
            "\n",
            "=== Test Set Label Distribution ===\n",
            "Benign (Label 0): 32\n",
            "Atypical (Label 1): 22\n",
            "Malignant (Label 2): 32\n",
            "\n",
            "\n",
            "394\n",
            "86\n",
            "65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.6502, 2.5256, 0.9381], device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/70]\n",
            "Train Loss: 0.9220, Train Acc: 0.3426, Train Precision: 0.3566, Train Recall: 0.3691, Train F1: 0.3297\n",
            "Val Loss:   0.9146, Val Acc:   0.2558, Val Precision: 0.0853, Val Recall: 0.3333, Val F1: 0.1358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/70: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/70]\n",
            "Train Loss: 0.8317, Train Acc: 0.2766, Train Precision: 0.3733, Train Recall: 0.3618, Train F1: 0.2768\n",
            "Val Loss:   0.9463, Val Acc:   0.2558, Val Precision: 0.0853, Val Recall: 0.3333, Val F1: 0.1358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/70: 100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/70]\n",
            "Train Loss: 0.7763, Train Acc: 0.3198, Train Precision: 0.3651, Train Recall: 0.3469, Train F1: 0.2971\n",
            "Val Loss:   0.8818, Val Acc:   0.2558, Val Precision: 0.0853, Val Recall: 0.3333, Val F1: 0.1358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/70]\n",
            "Train Loss: 0.6692, Train Acc: 0.4239, Train Precision: 0.5681, Train Recall: 0.4908, Train F1: 0.4354\n",
            "Val Loss:   0.8945, Val Acc:   0.4767, Val Precision: 0.3532, Val Recall: 0.5028, Val F1: 0.3986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/70: 100%|██████████| 25/25 [00:21<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/70]\n",
            "Train Loss: 0.6809, Train Acc: 0.5533, Train Precision: 0.5136, Train Recall: 0.5090, Train F1: 0.4980\n",
            "Val Loss:   0.7483, Val Acc:   0.4651, Val Precision: 0.3748, Val Recall: 0.5066, Val F1: 0.3959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/70]\n",
            "Train Loss: 0.5940, Train Acc: 0.4518, Train Precision: 0.6307, Train Recall: 0.5389, Train F1: 0.4628\n",
            "Val Loss:   0.8473, Val Acc:   0.3837, Val Precision: 0.5923, Val Recall: 0.4290, Val F1: 0.3709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/70]\n",
            "Train Loss: 0.4887, Train Acc: 0.6168, Train Precision: 0.6704, Train Recall: 0.6703, Train F1: 0.6018\n",
            "Val Loss:   0.7565, Val Acc:   0.4884, Val Precision: 0.4303, Val Recall: 0.5417, Val F1: 0.4202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/70: 100%|██████████| 25/25 [00:21<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/70]\n",
            "Train Loss: 0.4482, Train Acc: 0.6523, Train Precision: 0.7049, Train Recall: 0.7026, Train F1: 0.6358\n",
            "Val Loss:   0.7892, Val Acc:   0.5233, Val Precision: 0.6200, Val Recall: 0.5540, Val F1: 0.4722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/70: 100%|██████████| 25/25 [00:20<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/70]\n",
            "Train Loss: 0.4535, Train Acc: 0.6447, Train Precision: 0.6899, Train Recall: 0.6950, Train F1: 0.6243\n",
            "Val Loss:   1.0861, Val Acc:   0.6628, Val Precision: 0.6536, Val Recall: 0.6553, Val F1: 0.6534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/70: 100%|██████████| 25/25 [00:21<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/70]\n",
            "Train Loss: 0.4168, Train Acc: 0.6904, Train Precision: 0.7143, Train Recall: 0.7372, Train F1: 0.6669\n",
            "Val Loss:   0.8789, Val Acc:   0.6860, Val Precision: 0.6773, Val Recall: 0.6761, Val F1: 0.6763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/70: 100%|██████████| 25/25 [00:21<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/70]\n",
            "Train Loss: 0.4641, Train Acc: 0.7005, Train Precision: 0.7086, Train Recall: 0.7314, Train F1: 0.6734\n",
            "Val Loss:   0.9310, Val Acc:   0.5233, Val Precision: 0.6501, Val Recall: 0.5634, Val F1: 0.5222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/70]\n",
            "Train Loss: 0.5006, Train Acc: 0.5888, Train Precision: 0.6645, Train Recall: 0.6426, Train F1: 0.5774\n",
            "Val Loss:   0.7453, Val Acc:   0.4767, Val Precision: 0.5070, Val Recall: 0.5028, Val F1: 0.4486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/70]\n",
            "Train Loss: 0.4056, Train Acc: 0.7284, Train Precision: 0.7202, Train Recall: 0.7422, Train F1: 0.6923\n",
            "Val Loss:   1.0743, Val Acc:   0.4767, Val Precision: 0.5406, Val Recall: 0.4744, Val F1: 0.4446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/70]\n",
            "Train Loss: 0.3346, Train Acc: 0.7766, Train Precision: 0.7531, Train Recall: 0.8046, Train F1: 0.7415\n",
            "Val Loss:   1.4667, Val Acc:   0.5116, Val Precision: 0.5420, Val Recall: 0.4962, Val F1: 0.4747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/70]\n",
            "Train Loss: 0.2889, Train Acc: 0.7792, Train Precision: 0.7620, Train Recall: 0.8085, Train F1: 0.7452\n",
            "Val Loss:   1.0114, Val Acc:   0.5233, Val Precision: 0.6941, Val Recall: 0.5492, Val F1: 0.4693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/70: 100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/70]\n",
            "Train Loss: 0.2545, Train Acc: 0.7893, Train Precision: 0.7650, Train Recall: 0.8165, Train F1: 0.7535\n",
            "Val Loss:   0.8486, Val Acc:   0.5116, Val Precision: 0.5969, Val Recall: 0.5246, Val F1: 0.4557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/70: 100%|██████████| 25/25 [00:19<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/70]\n",
            "Train Loss: 0.3563, Train Acc: 0.6802, Train Precision: 0.7064, Train Recall: 0.7104, Train F1: 0.6536\n",
            "Val Loss:   0.6797, Val Acc:   0.7326, Val Precision: 0.7581, Val Recall: 0.7415, Val F1: 0.7314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/70: 100%|██████████| 25/25 [00:21<00:00,  1.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/70]\n",
            "Train Loss: 0.2575, Train Acc: 0.8299, Train Precision: 0.7899, Train Recall: 0.8419, Train F1: 0.7902\n",
            "Val Loss:   1.2720, Val Acc:   0.6744, Val Precision: 0.6703, Val Recall: 0.6562, Val F1: 0.6582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/70]\n",
            "Train Loss: 0.3305, Train Acc: 0.8096, Train Precision: 0.7753, Train Recall: 0.8298, Train F1: 0.7737\n",
            "Val Loss:   0.6248, Val Acc:   0.6744, Val Precision: 0.7349, Val Recall: 0.7036, Val F1: 0.6759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/70: 100%|██████████| 25/25 [00:19<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/70]\n",
            "Train Loss: 0.3160, Train Acc: 0.7563, Train Precision: 0.7543, Train Recall: 0.7988, Train F1: 0.7280\n",
            "Val Loss:   0.8861, Val Acc:   0.6163, Val Precision: 0.6418, Val Recall: 0.6278, Val F1: 0.6116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/70: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/70]\n",
            "Train Loss: 0.2635, Train Acc: 0.8173, Train Precision: 0.7729, Train Recall: 0.8190, Train F1: 0.7738\n",
            "Val Loss:   1.0427, Val Acc:   0.6744, Val Precision: 0.6689, Val Recall: 0.6562, Val F1: 0.6569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/70]\n",
            "Train Loss: 0.1975, Train Acc: 0.8756, Train Precision: 0.8257, Train Recall: 0.8825, Train F1: 0.8406\n",
            "Val Loss:   1.0816, Val Acc:   0.6744, Val Precision: 0.6625, Val Recall: 0.6515, Val F1: 0.6504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/70]\n",
            "Train Loss: 0.2274, Train Acc: 0.8706, Train Precision: 0.8209, Train Recall: 0.8807, Train F1: 0.8337\n",
            "Val Loss:   1.0787, Val Acc:   0.7093, Val Precision: 0.6947, Val Recall: 0.6686, Val F1: 0.6581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/70]\n",
            "Train Loss: 0.1961, Train Acc: 0.8782, Train Precision: 0.8272, Train Recall: 0.8878, Train F1: 0.8415\n",
            "Val Loss:   1.2938, Val Acc:   0.6628, Val Precision: 0.6834, Val Recall: 0.6174, Val F1: 0.5993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/70: 100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/70]\n",
            "Train Loss: 0.1344, Train Acc: 0.9213, Train Precision: 0.8753, Train Recall: 0.9324, Train F1: 0.8942\n",
            "Val Loss:   1.6110, Val Acc:   0.6512, Val Precision: 0.6415, Val Recall: 0.6259, Val F1: 0.6259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/70: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [26/70]\n",
            "Train Loss: 0.1103, Train Acc: 0.9492, Train Precision: 0.9101, Train Recall: 0.9593, Train F1: 0.9291\n",
            "Val Loss:   1.9329, Val Acc:   0.6279, Val Precision: 0.5708, Val Recall: 0.5767, Val F1: 0.5449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/70: 100%|██████████| 25/25 [00:19<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [27/70]\n",
            "Train Loss: 0.2242, Train Acc: 0.8909, Train Precision: 0.8395, Train Recall: 0.8957, Train F1: 0.8540\n",
            "Val Loss:   1.7705, Val Acc:   0.5930, Val Precision: 0.5623, Val Recall: 0.5549, Val F1: 0.5424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [28/70]\n",
            "Train Loss: 0.1509, Train Acc: 0.9188, Train Precision: 0.8695, Train Recall: 0.9157, Train F1: 0.8864\n",
            "Val Loss:   0.9532, Val Acc:   0.6163, Val Precision: 0.6165, Val Recall: 0.6042, Val F1: 0.6067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [29/70]\n",
            "Train Loss: 0.1925, Train Acc: 0.8756, Train Precision: 0.8219, Train Recall: 0.8774, Train F1: 0.8373\n",
            "Val Loss:   0.7398, Val Acc:   0.6279, Val Precision: 0.6748, Val Recall: 0.6572, Val F1: 0.6251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/70: 100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [30/70]\n",
            "Train Loss: 0.1341, Train Acc: 0.9239, Train Precision: 0.8776, Train Recall: 0.9300, Train F1: 0.8966\n",
            "Val Loss:   1.0415, Val Acc:   0.6512, Val Precision: 0.6396, Val Recall: 0.6402, Val F1: 0.6397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [31/70]\n",
            "Train Loss: 0.0816, Train Acc: 0.9492, Train Precision: 0.9122, Train Recall: 0.9553, Train F1: 0.9294\n",
            "Val Loss:   1.3895, Val Acc:   0.7093, Val Precision: 0.7109, Val Recall: 0.6828, Val F1: 0.6854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/70: 100%|██████████| 25/25 [00:19<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [32/70]\n",
            "Train Loss: 0.0400, Train Acc: 0.9721, Train Precision: 0.9451, Train Recall: 0.9723, Train F1: 0.9574\n",
            "Val Loss:   1.3971, Val Acc:   0.6860, Val Precision: 0.7029, Val Recall: 0.6619, Val F1: 0.6648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [33/70]\n",
            "Train Loss: 0.0546, Train Acc: 0.9670, Train Precision: 0.9442, Train Recall: 0.9668, Train F1: 0.9545\n",
            "Val Loss:   1.1173, Val Acc:   0.7209, Val Precision: 0.7282, Val Recall: 0.7074, Val F1: 0.7115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [34/70]\n",
            "Train Loss: 0.0312, Train Acc: 0.9797, Train Precision: 0.9556, Train Recall: 0.9846, Train F1: 0.9684\n",
            "Val Loss:   1.7508, Val Acc:   0.6744, Val Precision: 0.6489, Val Recall: 0.6326, Val F1: 0.6201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [35/70]\n",
            "Train Loss: 0.0343, Train Acc: 0.9772, Train Precision: 0.9614, Train Recall: 0.9782, Train F1: 0.9693\n",
            "Val Loss:   1.3838, Val Acc:   0.6860, Val Precision: 0.6697, Val Recall: 0.6619, Val F1: 0.6623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [36/70]\n",
            "Train Loss: 0.0349, Train Acc: 0.9848, Train Precision: 0.9751, Train Recall: 0.9853, Train F1: 0.9801\n",
            "Val Loss:   1.5772, Val Acc:   0.6744, Val Precision: 0.6740, Val Recall: 0.6420, Val F1: 0.6406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [37/70]\n",
            "Train Loss: 0.0064, Train Acc: 0.9949, Train Precision: 0.9877, Train Recall: 0.9960, Train F1: 0.9917\n",
            "Val Loss:   1.9411, Val Acc:   0.6744, Val Precision: 0.6835, Val Recall: 0.6326, Val F1: 0.6211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [38/70]\n",
            "Train Loss: 0.0043, Train Acc: 0.9975, Train Precision: 0.9937, Train Recall: 0.9983, Train F1: 0.9960\n",
            "Val Loss:   2.0731, Val Acc:   0.6860, Val Precision: 0.7139, Val Recall: 0.6430, Val F1: 0.6306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [39/70]\n",
            "Train Loss: 0.0203, Train Acc: 0.9949, Train Precision: 0.9921, Train Recall: 0.9952, Train F1: 0.9936\n",
            "Val Loss:   1.5867, Val Acc:   0.6977, Val Precision: 0.6829, Val Recall: 0.6818, Val F1: 0.6820\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/70: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [40/70]\n",
            "Train Loss: 0.0101, Train Acc: 0.9949, Train Precision: 0.9877, Train Recall: 0.9967, Train F1: 0.9921\n",
            "Val Loss:   1.8777, Val Acc:   0.6860, Val Precision: 0.6686, Val Recall: 0.6667, Val F1: 0.6670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [41/70]\n",
            "Train Loss: 0.0330, Train Acc: 0.9848, Train Precision: 0.9686, Train Recall: 0.9846, Train F1: 0.9761\n",
            "Val Loss:   1.7314, Val Acc:   0.6512, Val Precision: 0.6464, Val Recall: 0.6449, Val F1: 0.6421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [42/70]\n",
            "Train Loss: 0.0629, Train Acc: 0.9619, Train Precision: 0.9276, Train Recall: 0.9698, Train F1: 0.9451\n",
            "Val Loss:   2.0423, Val Acc:   0.6395, Val Precision: 0.6602, Val Recall: 0.5966, Val F1: 0.5825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [43/70]\n",
            "Train Loss: 0.0368, Train Acc: 0.9822, Train Precision: 0.9693, Train Recall: 0.9808, Train F1: 0.9747\n",
            "Val Loss:   1.9379, Val Acc:   0.6279, Val Precision: 0.6259, Val Recall: 0.6004, Val F1: 0.6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [44/70]\n",
            "Train Loss: 0.0050, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   1.6655, Val Acc:   0.6744, Val Precision: 0.6825, Val Recall: 0.6515, Val F1: 0.6558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/70: 100%|██████████| 25/25 [00:19<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [45/70]\n",
            "Train Loss: 0.0064, Train Acc: 0.9949, Train Precision: 0.9877, Train Recall: 0.9960, Train F1: 0.9917\n",
            "Val Loss:   1.7892, Val Acc:   0.6628, Val Precision: 0.6588, Val Recall: 0.6269, Val F1: 0.6213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/70: 100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [46/70]\n",
            "Train Loss: 0.0020, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   1.9088, Val Acc:   0.6628, Val Precision: 0.6733, Val Recall: 0.6269, Val F1: 0.6221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [47/70]\n",
            "Train Loss: 0.0020, Train Acc: 0.9975, Train Precision: 0.9937, Train Recall: 0.9983, Train F1: 0.9960\n",
            "Val Loss:   1.9533, Val Acc:   0.6628, Val Precision: 0.6733, Val Recall: 0.6269, Val F1: 0.6221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [48/70]\n",
            "Train Loss: 0.0014, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0439, Val Acc:   0.6512, Val Precision: 0.6652, Val Recall: 0.6165, Val F1: 0.6124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/70: 100%|██████████| 25/25 [00:19<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [49/70]\n",
            "Train Loss: 0.0011, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0365, Val Acc:   0.6512, Val Precision: 0.6652, Val Recall: 0.6165, Val F1: 0.6124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/70: 100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [50/70]\n",
            "Train Loss: 0.0027, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   1.8734, Val Acc:   0.6512, Val Precision: 0.6551, Val Recall: 0.6212, Val F1: 0.6195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [51/70]\n",
            "Train Loss: 0.0025, Train Acc: 0.9975, Train Precision: 0.9937, Train Recall: 0.9983, Train F1: 0.9960\n",
            "Val Loss:   1.9982, Val Acc:   0.6628, Val Precision: 0.6751, Val Recall: 0.6316, Val F1: 0.6311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [52/70]\n",
            "Train Loss: 0.0009, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0446, Val Acc:   0.6628, Val Precision: 0.6751, Val Recall: 0.6316, Val F1: 0.6311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/70: 100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [53/70]\n",
            "Train Loss: 0.0008, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0331, Val Acc:   0.6860, Val Precision: 0.6896, Val Recall: 0.6525, Val F1: 0.6508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/70: 100%|██████████| 25/25 [00:19<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [54/70]\n",
            "Train Loss: 0.0009, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0797, Val Acc:   0.6628, Val Precision: 0.6751, Val Recall: 0.6316, Val F1: 0.6311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/70: 100%|██████████| 25/25 [00:19<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [55/70]\n",
            "Train Loss: 0.0023, Train Acc: 0.9975, Train Precision: 0.9984, Train Recall: 0.9976, Train F1: 0.9980\n",
            "Val Loss:   2.0124, Val Acc:   0.6744, Val Precision: 0.6688, Val Recall: 0.6373, Val F1: 0.6308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [56/70]\n",
            "Train Loss: 0.0005, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   1.9999, Val Acc:   0.6744, Val Precision: 0.6877, Val Recall: 0.6420, Val F1: 0.6412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [57/70]\n",
            "Train Loss: 0.0005, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   1.9989, Val Acc:   0.6744, Val Precision: 0.6877, Val Recall: 0.6420, Val F1: 0.6412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [58/70]\n",
            "Train Loss: 0.0006, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0083, Val Acc:   0.6744, Val Precision: 0.6742, Val Recall: 0.6420, Val F1: 0.6400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 59/70: 100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [59/70]\n",
            "Train Loss: 0.0008, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0854, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 60/70: 100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [60/70]\n",
            "Train Loss: 0.0004, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.0992, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 61/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [61/70]\n",
            "Train Loss: 0.0004, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1086, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 62/70: 100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [62/70]\n",
            "Train Loss: 0.0006, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1400, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 63/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [63/70]\n",
            "Train Loss: 0.0004, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1514, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 64/70: 100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [64/70]\n",
            "Train Loss: 0.0005, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1513, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 65/70: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [65/70]\n",
            "Train Loss: 0.0004, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1507, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 66/70: 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [66/70]\n",
            "Train Loss: 0.0004, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1652, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 67/70: 100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [67/70]\n",
            "Train Loss: 0.0004, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1678, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 68/70: 100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [68/70]\n",
            "Train Loss: 0.0005, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1593, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 69/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [69/70]\n",
            "Train Loss: 0.0005, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1600, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 70/70: 100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [70/70]\n",
            "Train Loss: 0.0005, Train Acc: 1.0000, Train Precision: 1.0000, Train Recall: 1.0000, Train F1: 1.0000\n",
            "Val Loss:   2.1594, Val Acc:   0.6860, Val Precision: 0.6972, Val Recall: 0.6525, Val F1: 0.6506\n",
            "Best Val: 0.7325581395348837\n",
            "Test Loss: 0.9613, Test Acc: 0.6462, Test Precision: 0.6643, Test Recall: 0.5984, Test F1: 0.5975\n",
            "Final test metrics saved with Arial font and colored by Order Method.\n",
            "Best Val: 0.7325581395348837\n",
            "Test Loss: 0.9613, Test Acc: 0.6462, Test Precision: 0.6643, Test Recall: 0.5984, Test F1: 0.5975\n"
          ]
        },
        {
          "data": {
            "application/javascript": "new Audio(\"https://actions.google.com/sounds/v1/alarms/alarm_clock.ogg\").play()",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install gspread oauth2client\n",
        "!pip install hilbertcurve\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "from IPython.display import Javascript, display\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "##########################\n",
        "# Configuration\n",
        "##########################\n",
        "DATA_DIR = \"/content/drive/MyDrive/BRACS/MyTransformer\"\n",
        "\n",
        "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
        "VAL_CSV = os.path.join(DATA_DIR, \"val.csv\")\n",
        "TEST_CSV = os.path.join(DATA_DIR, \"test.csv\")\n",
        "\n",
        "TRAIN_EMBED_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "VAL_EMBED_DIR = os.path.join(DATA_DIR, \"val\")\n",
        "TEST_EMBED_DIR = os.path.join(DATA_DIR, \"test\")\n",
        "\n",
        "NUM_CLASSES = 3\n",
        "EMBED_DIM = 1536\n",
        "MAX_TILES = 600\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-4\n",
        "EPOCHS = 70\n",
        "\n",
        "# Parameter For Testing Ordering Methods\n",
        "# spiral or 2dsinusodial or rasterscan\n",
        "# or rasterscanwencoding or spiralwencoding\n",
        "ORDER_METHOD = \"spiralwencoding\";\n",
        "# Scaling factor (alpha) that controls the influence/weight of positional encoding\n",
        "ALPHA_ENCOD = 1;\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Create an experiment folder with timestamp\n",
        "timestamp = datetime.datetime.now().strftime(\"%d.%m-%H:%M\")\n",
        "EXP_DIR = f\"/content/drive/MyDrive/BRACS/experiments/{ORDER_METHOD}/{ALPHA_ENCOD}-{timestamp}-2d-6head4layer-70epoch-drop20-focalLoss\"\n",
        "print(\"Experiment directory set to: \", EXP_DIR)\n",
        "CHECKPOINT_DIR = os.path.join(EXP_DIR, \"checkpoints\")\n",
        "PLOTS_DIR = os.path.join(EXP_DIR, \"plots\")\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# New Metrics\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "train_f1s = []\n",
        "\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_f1s = []\n",
        "\n",
        "##########################\n",
        "# 2D Sinusoidal Position Embedding Functions\n",
        "##########################\n",
        "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
        "    \"\"\"\n",
        "    grid_size: int (same for height and width)\n",
        "    return: pos_embed of shape\n",
        "        [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim]\n",
        "    \"\"\"\n",
        "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
        "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
        "    grid = np.meshgrid(grid_w, grid_h)  # w first\n",
        "    grid = np.stack(grid, axis=0)\n",
        "\n",
        "    # example\n",
        "    # grid_h = [0, 1, 2]  # y-coordinates (rows)\n",
        "    # grid_w = [0, 1, 2]  # x-coordinates (columns)\n",
        "\n",
        "    # grid = np.meshgrid(grid_w, grid_h)\n",
        "\n",
        "    # grid =\n",
        "    # [[[0 1 2]   # X-coordinates (width)\n",
        "    #   [0 1 2]\n",
        "    #   [0 1 2]]\n",
        "\n",
        "    # [[0 0 0]   # Y-coordinates (height)\n",
        "    #   [1 1 1]\n",
        "    #   [2 2 2]]]\n",
        "\n",
        "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
        "    if cls_token:\n",
        "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
        "    return pos_embed\n",
        "\n",
        "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
        "    assert embed_dim % 2 == 0\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])\n",
        "    emb = np.concatenate([emb_h, emb_w], axis=1)\n",
        "    return emb\n",
        "\n",
        "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
        "    assert embed_dim % 2 == 0\n",
        "    omega = np.arange(embed_dim // 2, dtype=float)\n",
        "    omega /= embed_dim / 2.0\n",
        "    omega = 1.0 / (10000 ** omega)\n",
        "\n",
        "    pos = pos.reshape(-1)\n",
        "    out = np.einsum(\"m,d->md\", pos, omega)\n",
        "    emb_sin = np.sin(out)\n",
        "    emb_cos = np.cos(out)\n",
        "    emb = np.concatenate([emb_sin, emb_cos], axis=1)\n",
        "    return emb\n",
        "\n",
        "##########################\n",
        "# Dataset\n",
        "##########################\n",
        "def get_1d_sincos_pos_embed(embed_dim, seq_len):\n",
        "        \"\"\"\n",
        "        Generate 1D sinusoidal positional embeddings\n",
        "        embed_dim: Embedding dimension (e.g., 1536)\n",
        "        seq_len: The sequence length (e.g., number of tiles)\n",
        "        \"\"\"\n",
        "        positions = torch.arange(seq_len).unsqueeze(1).float()  # Shape: [seq_len, 1]\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))  # Shape: [embed_dim//2]\n",
        "\n",
        "        # Apply sine and cosine functions\n",
        "        pos_encoding = torch.zeros(seq_len, embed_dim)\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions * div_term)  # Even dimensions: Apply sin\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions * div_term)  # Odd dimensions: Apply cos\n",
        "\n",
        "        return pos_encoding\n",
        "\n",
        "class WSIDataset(Dataset):\n",
        "    def __init__(self, df, embed_dir, max_tiles=600, order_method=\"rasterscan\", transform=None):\n",
        "        self.df = df\n",
        "        self.embed_dir = embed_dir\n",
        "        self.max_tiles = max_tiles\n",
        "        self.transform = transform\n",
        "        self.order_method = order_method\n",
        "\n",
        "        # We pre-generate a 1000 x 1000 grid of position embeddings.\n",
        "        pos_embed_2d = get_2d_sincos_pos_embed(\n",
        "            embed_dim=EMBED_DIM,\n",
        "            grid_size=800,     # as per your instruction\n",
        "            cls_token=False\n",
        "        )\n",
        "        # Convert to torch.Tensor\n",
        "        self.pos_embed_2d = torch.from_numpy(pos_embed_2d).float()  # shape [1000*1000, EMBED_DIM]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        slide_id = row['slide_id']\n",
        "        label = int(row['label'])\n",
        "\n",
        "        # Load the embedding\n",
        "        embed_path = os.path.join(self.embed_dir, f\"{slide_id}.pt\")\n",
        "        data = torch.load(embed_path)\n",
        "        tile_embeds = data[\"tile_embeds\"]  # [N, EMBED_DIM]\n",
        "\n",
        "        # If coords are available, reorder tiles\n",
        "        if \"coords\" in data:\n",
        "            coords = data[\"coords\"]  # coords is [N, 2] with (x, y)\n",
        "\n",
        "            if(self.order_method == \"spiral\"):\n",
        "                tile_embeds = self.get_spiral_order_embeddings(coords, tile_embeds)\n",
        "                seq_len = tile_embeds.shape[0]\n",
        "\n",
        "            elif(self.order_method == \"spiralwencoding\"):\n",
        "                tile_embeds = self.get_spiral_order_embeddings(coords, tile_embeds)\n",
        "                seq_len = tile_embeds.shape[0]\n",
        "                pos_encoding = get_1d_sincos_pos_embed(EMBED_DIM, seq_len)\n",
        "                tile_embeds = tile_embeds + (ALPHA_ENCOD * pos_encoding)\n",
        "\n",
        "            elif(self.order_method == \"rasterscan\"):\n",
        "                #  sort the tiles by their coordinates to ensure row major ordering\n",
        "                sorted_indices = torch.argsort(coords[:,0] + coords[:,1] * 100000)\n",
        "                tile_embeds = tile_embeds[sorted_indices]\n",
        "                seq_len = tile_embeds.shape[0]\n",
        "\n",
        "            elif(self.order_method == \"rasterscanwencoding\"):\n",
        "                #  sort the tiles by their coordinates to ensure row major ordering\n",
        "                sorted_indices = torch.argsort(coords[:,0] + coords[:,1] * 100000)\n",
        "                tile_embeds = tile_embeds[sorted_indices]\n",
        "                seq_len = tile_embeds.shape[0]\n",
        "                pos_encoding = get_1d_sincos_pos_embed(EMBED_DIM, seq_len)\n",
        "                tile_embeds = tile_embeds + (ALPHA_ENCOD * pos_encoding)\n",
        "\n",
        "            elif(self.order_method == \"2dsinusodial\"):\n",
        "                original_embeds_before_pos = tile_embeds.clone() # Keep a copy before adding PE\n",
        "                tile_embeds = self.apply_2d_position_embed(tile_embeds, coords)\n",
        "                coords_for_pe = torch.floor(coords / 256.0)\n",
        "                x_coords = coords_for_pe[:, 0].numpy()\n",
        "                y_coords = coords_for_pe[:, 1].numpy()\n",
        "                pos_1d_list = [int(y_c * 800 + x_c) for x_c, y_c in zip(x_coords, y_coords)]\n",
        "                pos_1d_tensor = torch.tensor(pos_1d_list, dtype=torch.long)\n",
        "                positional_embeddings_2d = self.pos_embed_2d[pos_1d_tensor]\n",
        "                # print(\"2D Positional Embeddings Min:\", positional_embeddings_2d.min().item())\n",
        "                # print(\"2D Positional Embeddings Max:\", positional_embeddings_2d.max().item())\n",
        "                # print(\"-\" * 30)\n",
        "\n",
        "            elif self.order_method == \"hilbertwencoding\":\n",
        "                tile_embeds = self.get_hilbert_order_embeddings(coords, tile_embeds, visualize=True)\n",
        "                seq_len = tile_embeds.shape[0]\n",
        "                pos_encoding = get_1d_sincos_pos_embed(EMBED_DIM, seq_len)\n",
        "                tile_embeds = tile_embeds + (ALPHA_ENCOD * pos_encoding)\n",
        "\n",
        "        # Pad/truncate to MAX_TILES\n",
        "        num_tiles = tile_embeds.shape[0]\n",
        "        if num_tiles > self.max_tiles:\n",
        "            tile_embeds = tile_embeds[:self.max_tiles]\n",
        "        elif num_tiles < self.max_tiles:\n",
        "            pad_len = self.max_tiles - num_tiles\n",
        "            pad_embeds = torch.zeros(pad_len, EMBED_DIM)\n",
        "            tile_embeds = torch.cat([tile_embeds, pad_embeds], dim=0)\n",
        "\n",
        "        if self.transform:\n",
        "            tile_embeds = self.transform(tile_embeds)\n",
        "\n",
        "        return tile_embeds, label\n",
        "\n",
        "    def apply_2d_position_embed(self, tile_embeds, coords_):\n",
        "        \"\"\"\n",
        "        Apply 2D sincos positional embeddings based on (x,y) coords\n",
        "        (divided by 256 => up to a 1000x1000 grid).\n",
        "        \"\"\"\n",
        "        coords = torch.floor(coords_ / 256.0)  # dividing by tile_size=256\n",
        "        x_coords = coords[:, 0].numpy()\n",
        "        y_coords = coords[:, 1].numpy()\n",
        "\n",
        "        # Build 1D positions\n",
        "        pos_1d_list = []\n",
        "        for i in range(len(x_coords)):\n",
        "            x_c = int(x_coords[i])\n",
        "            y_c = int(y_coords[i])\n",
        "            pos_1d = y_c * 800 + x_c\n",
        "            pos_1d_list.append(pos_1d)\n",
        "\n",
        "        pos_1d_tensor = torch.tensor(pos_1d_list, dtype=torch.long)\n",
        "        # Add the 2D positional embeddings\n",
        "        tile_embeds = tile_embeds + self.pos_embed_2d[pos_1d_tensor]\n",
        "\n",
        "        return tile_embeds\n",
        "\n",
        "####################################################\n",
        "#         # hilbert order method\n",
        "####################################################\n",
        "    def get_hilbert_order_embeddings(self, coords_, tile_embeds, visualize=True):\n",
        "        \"\"\"\n",
        "        Arrange tile embeddings in Hilbert curve order and visualize traversal if visualize=True.\n",
        "\n",
        "        Args:\n",
        "            coords_ (torch.Tensor): Tensor of shape [N, 2] with (x, y) coordinates.\n",
        "            tile_embeds (torch.Tensor): Tensor of shape [N, EMBED_DIM].\n",
        "            visualize (bool): Whether to plot the Hilbert traversal or not.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Tensor of shape [num_tiles, EMBED_DIM] arranged in Hilbert order.\n",
        "        \"\"\"\n",
        "        import hilbertcurve.hilbertcurve as hilbert_lib\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        coords = torch.floor(coords_ / 256.0)  # Tile size normalization\n",
        "        x_coords = coords[:, 0].numpy()\n",
        "        y_coords = coords[:, 1].numpy()\n",
        "\n",
        "        # Normalize\n",
        "        min_x, max_x = int(np.min(x_coords)), int(np.max(x_coords))\n",
        "        min_y, max_y = int(np.min(y_coords)), int(np.max(y_coords))\n",
        "        norm_x = x_coords - min_x\n",
        "        norm_y = y_coords - min_y\n",
        "\n",
        "        width = int(max_x - min_x + 1)\n",
        "        height = int(max_y - min_y + 1)\n",
        "\n",
        "        max_dim = max(width, height)\n",
        "        grid_size = 1\n",
        "        while grid_size < max_dim:\n",
        "            grid_size *= 2\n",
        "\n",
        "        p = int(np.log2(grid_size))\n",
        "        hilbert_curve = hilbert_lib.HilbertCurve(p, 2)\n",
        "\n",
        "        hilbert_indices = []\n",
        "        for x, y in zip(norm_x, norm_y):\n",
        "            if x < grid_size and y < grid_size:\n",
        "                hilbert_distance = hilbert_curve.distance_from_point([int(x), int(y)])\n",
        "                hilbert_indices.append(hilbert_distance)\n",
        "            else:\n",
        "                hilbert_indices.append(float('inf'))\n",
        "\n",
        "        hilbert_indices = np.array(hilbert_indices)\n",
        "        sorted_indices = np.argsort(hilbert_indices)\n",
        "\n",
        "        hilbert_order_embeds = tile_embeds[sorted_indices]\n",
        "\n",
        "        if visualize:\n",
        "            sorted_coords = np.vstack((norm_x[sorted_indices], norm_y[sorted_indices])).T\n",
        "\n",
        "            plt.figure(figsize=(8, 8))\n",
        "            plt.scatter(norm_x, norm_y, c=\"blue\", alpha=0.5, label=\"Original Tiles\")\n",
        "            plt.plot(sorted_coords[:, 0], sorted_coords[:, 1], color=\"red\", linewidth=1.5, linestyle=\"dashed\", label=\"Hilbert Path\")\n",
        "            plt.scatter(sorted_coords[:, 0], sorted_coords[:, 1], c=\"red\", label=\"Hilbert Tiles\")\n",
        "\n",
        "            for i, (x, y) in enumerate(sorted_coords[:10]):\n",
        "                plt.text(x, y, str(i), fontsize=10, color=\"black\")\n",
        "\n",
        "            plt.xlabel(\"X Coordinate (Normalized)\")\n",
        "            plt.ylabel(\"Y Coordinate (Normalized)\")\n",
        "            plt.title(\"Hilbert Curve Traversal of Tiles\")\n",
        "            plt.gca().invert_yaxis()\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "        return hilbert_order_embeds\n",
        "\n",
        "####################################################\n",
        "#         # ORIGINAL METHOD FOR SPIRAL ORDER\n",
        "####################################################\n",
        "    def get_spiral_order_embeddings(self, coords_, tile_embeds):\n",
        "        \"\"\"\n",
        "        Arrange tile embeddings in a spiral order without padding for missing tiles.\n",
        "\n",
        "        Args:\n",
        "            coords_ (torch.Tensor): Tensor of shape [N, 2] with (x, y) coordinates.\n",
        "            tile_embeds (torch.Tensor): Tensor of shape [N, EMBED_DIM].\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Tensor of shape [num_tiles, EMBED_DIM] arranged in spiral order.\n",
        "        \"\"\"\n",
        "        # Convert coordinates to integer grid indices\n",
        "\n",
        "        coords = torch.floor(coords_ / 256.0) # Tile size\n",
        "\n",
        "        x_coords = coords[:, 0].numpy()\n",
        "        y_coords = coords[:, 1].numpy()\n",
        "\n",
        "        # Normalize coordinates to start from (0,0)\n",
        "        min_x, max_x = int(np.min(x_coords)), int(np.max(x_coords))\n",
        "        min_y, max_y = int(np.min(y_coords)), int(np.max(y_coords))\n",
        "        norm_x = x_coords - min_x\n",
        "        norm_y = y_coords - min_y\n",
        "\n",
        "        width = int(max_x - min_x + 1)\n",
        "        height = int(max_y - min_y + 1)\n",
        "\n",
        "        # Create a grid mapping from (x, y) to embedding index\n",
        "        grid = {}\n",
        "        for idx, (x, y) in enumerate(zip(norm_x, norm_y)):\n",
        "            grid[(x, y)] = idx\n",
        "\n",
        "        # Generate spiral order coordinates\n",
        "        spiral_coords = self.generate_spiral_coords(width, height)\n",
        "\n",
        "        # Collect tile embeddings in spiral order\n",
        "        spiral_order = []\n",
        "        for coord in spiral_coords:\n",
        "            idx = grid.get(coord)\n",
        "            if idx is not None:\n",
        "                spiral_order.append(tile_embeds[idx])\n",
        "\n",
        "        # Convert list to tensor\n",
        "        if len(spiral_order) == 0:\n",
        "            # Handle case with no tiles\n",
        "            print(\"!----- Spiral list is empty\")\n",
        "            return torch.zeros(0, self.embed_dim)\n",
        "        spiral_embeds = torch.stack(spiral_order)  # [num_tiles, EMBED_DIM]\n",
        "\n",
        "        return spiral_embeds\n",
        "####################################################\n",
        "##    END ORIGINAL METHOD FOR SPIRAL ORDER\n",
        "####################################################\n",
        "\n",
        "    def generate_spiral_coords(self, width, height):\n",
        "            \"\"\"\n",
        "            Generate coordinates in spiral order starting from the top-left corner.\n",
        "\n",
        "            Args:\n",
        "                width (int): Number of columns in the grid.\n",
        "                height (int): Number of rows in the grid.\n",
        "\n",
        "            Returns:\n",
        "                list of tuples: List of (x, y) coordinates in spiral order.\n",
        "            \"\"\"\n",
        "            spiral_order = []\n",
        "            top, bottom = 0, height - 1\n",
        "            left, right = 0, width - 1\n",
        "\n",
        "            while top <= bottom and left <= right:\n",
        "                # Traverse from Left to Right\n",
        "                for x in range(left, right + 1):\n",
        "                    spiral_order.append((x, top))\n",
        "                top += 1\n",
        "\n",
        "                # Traverse from Top to Bottom\n",
        "                for y in range(top, bottom + 1):\n",
        "                    spiral_order.append((right, y))\n",
        "                right -= 1\n",
        "\n",
        "                if top <= bottom:\n",
        "                    # Traverse from Right to Left\n",
        "                    for x in range(right, left - 1, -1):\n",
        "                        spiral_order.append((x, bottom))\n",
        "                    bottom -= 1\n",
        "\n",
        "                if left <= right:\n",
        "                    # Traverse from Bottom to Top\n",
        "                    for y in range(bottom, top - 1, -1):\n",
        "                        spiral_order.append((left, y))\n",
        "                    left += 1\n",
        "\n",
        "            return spiral_order\n",
        "\n",
        "##########################\n",
        "# Sinusoidal Positional Encoding\n",
        "##########################\n",
        "class SinusoidalPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=601):  # +1 for CLS\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        x = x + self.pe[:seq_len, :]\n",
        "        return x\n",
        "\n",
        "##########################\n",
        "# Transformer Model with Dropout and MLP Head\n",
        "##########################\n",
        "class WSITransformer(nn.Module):\n",
        "    def __init__(self, embed_dim=1536, num_heads=8, num_layers=4, ff_dim=4096, num_classes=3, max_tiles=600, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # CLS token\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        nn.init.normal_(self.cls_token, std=0.02)\n",
        "\n",
        "        self.pos_encoder = SinusoidalPositionalEncoding(d_model=embed_dim, max_len=max_tiles+1)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim,\n",
        "                                                   nhead=num_heads,\n",
        "                                                   dim_feedforward=ff_dim,\n",
        "                                                   dropout=dropout,\n",
        "                                                   batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Classification head: MLP with dropout\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim, embed_dim//2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim//2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, d = x.shape\n",
        "\n",
        "        # CLS token\n",
        "        cls_tokens = self.cls_token.expand(b, -1, -1)\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "\n",
        "        # Pos encoding/ Don't apply if 2D sinusodial\n",
        "        #x = self.pos_encoder(x)  --------->??????\n",
        "\n",
        "        # Transformer\n",
        "        x = self.transformer_encoder(x)\n",
        "\n",
        "        # CLS output\n",
        "        cls_out = x[:, 0, :]\n",
        "        logits = self.classifier(cls_out)\n",
        "        return logits\n",
        "\n",
        "########################\n",
        "### Loss\n",
        "########################\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss for multi-class classification\n",
        "    Reference:\n",
        "    https://arxiv.org/pdf/1708.02002.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            alpha (float or list, optional): Weighting factor for each class. Default is None.\n",
        "            gamma (float): Focusing parameter for modulating factor (1-p).\n",
        "            reduction (str): Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'.\n",
        "        \"\"\"\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha, (list, np.ndarray)):\n",
        "            self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: Predictions of the model (logits) with shape [batch_size, num_classes].\n",
        "            targets: Ground truth labels with shape [batch_size].\n",
        "        \"\"\"\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha.to(inputs.device) if self.alpha is not None else None)\n",
        "        pt = torch.exp(-ce_loss)  # prevents nans when probability 0\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "##########################\n",
        "# Data Preparation\n",
        "##########################\n",
        "def print_label_distribution(df, split_name):\n",
        "    label_names = {0: 'Benign', 1: 'Atypical', 2: 'Malignant'}\n",
        "\n",
        "    counts = df['label'].value_counts().sort_index()\n",
        "    print(f\"=== {split_name} Set Label Distribution ===\")\n",
        "    for label in sorted(counts.index):\n",
        "        label_name = label_names.get(label, f\"Unknown ({label})\")\n",
        "        count = counts[label]\n",
        "        print(f\"{label_name} (Label {label}): {count}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "val_df = pd.read_csv(VAL_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "\n",
        "# Initialize datasets with their respective embedding directories\n",
        "train_dataset = WSIDataset(train_df, TRAIN_EMBED_DIR, max_tiles=MAX_TILES, order_method=ORDER_METHOD)\n",
        "test_dataset = WSIDataset(val_df, VAL_EMBED_DIR, max_tiles=MAX_TILES, order_method=ORDER_METHOD)\n",
        "val_dataset = WSIDataset(test_df, TEST_EMBED_DIR, max_tiles=MAX_TILES, order_method=ORDER_METHOD)\n",
        "\n",
        "print(\"ORDER METHOD\", ORDER_METHOD )\n",
        "\n",
        "print_label_distribution(train_df, \"Train\")\n",
        "print_label_distribution(val_df, \"Validation\")\n",
        "print_label_distribution(test_df, \"Test\")\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "print(len(test_dataset))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "##########################\n",
        "# Training Setup\n",
        "##########################\n",
        "model = WSITransformer(embed_dim=EMBED_DIM,\n",
        "                       num_heads=6,\n",
        "                       num_layers=4,\n",
        "                       ff_dim=4096,\n",
        "                       num_classes=NUM_CLASSES,\n",
        "                       max_tiles=MAX_TILES,\n",
        "                       dropout=0.20).to(device)\n",
        "\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_df['label']), y=train_df['label'])\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "# Initialize FocalLoss with class weights\n",
        "print(class_weights)\n",
        "criterion = FocalLoss(gamma=1, alpha=class_weights, reduction='mean')\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "\n",
        "# ADDING A LEARNING RATE SCHEDULER\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "##########################\n",
        "# Evaluation Function\n",
        "##########################\n",
        "def evaluate(model, loader, criterion, compute_metrics=True):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for tile_embeds, labels in loader:\n",
        "            tile_embeds = tile_embeds.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(tile_embeds)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item() * tile_embeds.size(0)\n",
        "            _, predicted = torch.max(logits, dim=1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            if compute_metrics:\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "    avg_loss = total_loss / total if total > 0 else 0\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    if compute_metrics:\n",
        "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "        return avg_loss, accuracy, precision, recall, f1, all_preds, all_labels\n",
        "    else:\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "\n",
        "##########################\n",
        "# Training Loop\n",
        "##########################\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    for tile_embeds, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        tile_embeds = tile_embeds.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(tile_embeds)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * tile_embeds.size(0)\n",
        "        _, predicted = torch.max(logits, dim=1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        all_train_preds.extend(predicted.cpu().numpy())\n",
        "        all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_loss = epoch_loss / total if total > 0 else 0\n",
        "    train_acc = correct / total if total > 0 else 0\n",
        "    train_precision = precision_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_recall = recall_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_precisions.append(train_precision)\n",
        "    train_recalls.append(train_recall)\n",
        "    train_f1s.append(train_f1)\n",
        "\n",
        "    val_loss, val_acc, val_precision, val_recall, val_f1, temp1 , temp2 = evaluate(model, val_loader, criterion)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "    # Step the scheduler with validation loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f}\")\n",
        "    print(f\"Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, \"best_model.pth\"))\n",
        "    torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"model_epoch_{epoch+1}.pth\"))\n",
        "\n",
        "##########################\n",
        "# Evaluate on Test Set\n",
        "##########################\n",
        "model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, \"best_model.pth\"), map_location=device))\n",
        "print(f\"Best Val: {best_val_acc}\")\n",
        "test_loss, test_acc, test_precision, test_recall, test_f1, test_labels, test_preds = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}\")\n",
        "\n",
        "# Define Label Names\n",
        "label_names = ['Benign', 'Atypical', 'Malignant']\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
        "plt.xlabel('True Label')\n",
        "plt.ylabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'confusion_matrix.png'))\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# Plotting Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, EPOCHS+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, EPOCHS+1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'loss_curve.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, EPOCHS+1), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(1, EPOCHS+1), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'accuracy_curve.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plotting Precision\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, EPOCHS+1), train_precisions, label='Train Precision')\n",
        "plt.plot(range(1, EPOCHS+1), val_precisions, label='Validation Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'precision_curve.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plotting Recall\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, EPOCHS+1), train_recalls, label='Train Recall')\n",
        "plt.plot(range(1, EPOCHS+1), val_recalls, label='Validation Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'recall_curve.png'))\n",
        "plt.close()\n",
        "\n",
        "# Plotting F1-Score\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, EPOCHS+1), train_f1s, label='Train F1-Score')\n",
        "plt.plot(range(1, EPOCHS+1), val_f1s, label='Validation F1-Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.title('F1-Score Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'f1_score_curve.png'))\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# Save metrics and parameters to a text file\n",
        "with open(os.path.join(EXP_DIR, \"experiment_details.txt\"), \"w\") as f:\n",
        "    f.write(\"Experiment Configuration:\\n\")\n",
        "    f.write(f\"Timestamp: {timestamp}\\n\")\n",
        "    f.write(f\"NUM_CLASSES: {NUM_CLASSES}\\n\")\n",
        "    f.write(f\"EMBED_DIM: {EMBED_DIM}\\n\")\n",
        "    f.write(f\"MAX_TILES: {MAX_TILES}\\n\")\n",
        "    f.write(f\"BATCH_SIZE: {BATCH_SIZE}\\n\")\n",
        "    f.write(f\"LR: {LR}\\n\")\n",
        "    f.write(f\"EPOCHS: {EPOCHS}\\n\")\n",
        "    f.write(f\"Model Architecture:\\n{model}\\n\")\n",
        "    f.write(\"\\nTraining Metrics:\\n\")\n",
        "    f.write(\"Epoch\\tTrain Loss\\tTrain Acc\\tTrain Precision\\tTrain Recall\\tTrain F1\\tVal Loss\\tVal Acc\\tVal Precision\\tVal Recall\\tVal F1\\n\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        f.write(f\"{epoch+1}\\t\")\n",
        "        f.write(f\"{train_losses[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{train_accuracies[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{train_precisions[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{train_recalls[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{train_f1s[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{val_losses[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{val_accuracies[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{val_precisions[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{val_recalls[epoch]:.4f}\\t\")\n",
        "        f.write(f\"{val_f1s[epoch]:.4f}\\n\")\n",
        "\n",
        "\n",
        "    f.write(f\"\\nORDER_METHOD: {ORDER_METHOD}\\n\")\n",
        "    f.write(f\"ALPHA_ENCOD: {ALPHA_ENCOD}\\n\")\n",
        "    f.write(f\"\\nBest Validation Accuracy: {best_val_acc:.4f}\\n\")\n",
        "    f.write(f\"Test Metrics:\\n\")\n",
        "    f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n",
        "    f.write(f\"Test Acc: {test_acc:.4f}\\n\")\n",
        "    f.write(f\"Test Precision: {test_precision:.4f}\\n\")\n",
        "    f.write(f\"Test Recall: {test_recall:.4f}\\n\")\n",
        "    f.write(f\"Test F1-Score: {test_f1:.4f}\\n\")\n",
        "\n",
        "\n",
        "##########################\n",
        "# Save Final Test Metrics to Excel\n",
        "##########################\n",
        "import pandas as pd\n",
        "import os\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.styles import PatternFill, Font\n",
        "\n",
        "# Create a dictionary for the final 9 metrics\n",
        "final_metrics = {\n",
        "    \"Order\": ORDER_METHOD,\n",
        "    \"Alpha\": ALPHA_ENCOD,\n",
        "    \"Timestamp\": timestamp,\n",
        "    \"Best Val Accuracy\": round(float(best_val_acc), 4),\n",
        "    \"Test Loss\": round(float(test_loss), 4),\n",
        "    \"Test Accuracy\": round(float(test_acc), 4),\n",
        "    \"Test Precision\": round(float(test_precision), 4),\n",
        "    \"Test Recall\": round(float(test_recall), 4),\n",
        "    \"Test F1-Score\": round(float(test_f1), 4)\n",
        "}\n",
        "\n",
        "# Convert to single-row DataFrame\n",
        "df_final_metrics = pd.DataFrame([final_metrics])\n",
        "\n",
        "# Path to Excel file\n",
        "metrics_path = os.path.join(\"/content/drive/MyDrive/BRACS/experiments/\", \"final_test_metrics.xlsx\")\n",
        "\n",
        "# If file exists, load and append\n",
        "if os.path.exists(metrics_path):\n",
        "    df_existing = pd.read_excel(metrics_path)\n",
        "    df_final = pd.concat([df_existing, df_final_metrics], ignore_index=True)\n",
        "else:\n",
        "    df_final = df_final_metrics\n",
        "\n",
        "# First: save the plain DataFrame without styles\n",
        "df_final.to_excel(metrics_path, index=False)\n",
        "\n",
        "# Now reopen and apply styles safely\n",
        "wb = load_workbook(metrics_path)\n",
        "ws = wb.active\n",
        "\n",
        "# Define fills for each Order Method\n",
        "fill_colors = {\n",
        "    \"spiral\":           \"ADD8E6\",  # Light Blue\n",
        "    \"spiralwencoding\":  \"87CEEB\",  # Sky Blue\n",
        "    \"2dsinusodial\":     \"98FB98\",  # Pale Green\n",
        "    \"rasterscan\":       \"FFB6C1\",  # Light Pink\n",
        "    \"rasterscanwencoding\": \"FFD700\",  # Gold\n",
        "    \"hilbertwencoding\": \"9370DB\",  # Medium Purple\n",
        "}\n",
        "\n",
        "# Apply font and coloring\n",
        "for row_idx in range(2, ws.max_row + 1):  # Skip header row (start from 2)\n",
        "    order_method = ws[f\"A{row_idx}\"].value\n",
        "    fill_color = fill_colors.get(order_method, None)\n",
        "\n",
        "    for col_idx in range(1, ws.max_column + 1):\n",
        "        cell = ws.cell(row=row_idx, column=col_idx)\n",
        "\n",
        "        # Apply Arial font\n",
        "        cell.font = Font(name='Arial', size=11)\n",
        "\n",
        "        # Apply background color if matching\n",
        "        if fill_color:\n",
        "            cell.fill = PatternFill(start_color=fill_color, end_color=fill_color, fill_type=\"solid\")\n",
        "\n",
        "# Also set header font to Arial\n",
        "for col_idx in range(1, ws.max_column + 1):\n",
        "    cell = ws.cell(row=1, column=col_idx)\n",
        "    cell.font = Font(name='Arial', bold=True, size=12)\n",
        "\n",
        "# Save workbook\n",
        "wb.save(metrics_path)\n",
        "\n",
        "print(\"Final test metrics saved with Arial font and colored by Order Method.\")\n",
        "\n",
        "##########################\n",
        "# End Save Final Test Metrics to Excel\n",
        "##########################\n",
        "\n",
        "# Load best model before testing\n",
        "model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, \"best_model.pth\"), map_location=device))\n",
        "print(f\"Best Val: {best_val_acc}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc, test_precision, test_recall, test_f1, test_labels, test_preds = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}, Test F1: {test_f1:.4f}\")\n",
        "\n",
        "\n",
        "beep()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_Ti15RyI-Cc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# #####################################################\n",
        "#           # METHOD WITH VISUALIZER FOR SPIRAL ORDER\n",
        "# #####################################################\n",
        "    # def get_spiral_order_embeddings(self, coords_, tile_embeds):\n",
        "    #     \"\"\"\n",
        "    #     Arrange tile embeddings in a spiral order and visualize traversal.\n",
        "\n",
        "    #     Args:\n",
        "    #         coords_ (torch.Tensor): Tensor of shape [N, 2] with (x, y) coordinates.\n",
        "    #         tile_embeds (torch.Tensor): Tensor of shape [N, EMBED_DIM].\n",
        "\n",
        "    #     Returns:\n",
        "    #         torch.Tensor: Tensor of shape [num_tiles, EMBED_DIM] arranged in spiral order.\n",
        "    #     \"\"\"\n",
        "    #     # Convert coordinates to integer grid indices\n",
        "    #     coords = torch.floor(coords_ / 256.0)  # Tile size\n",
        "\n",
        "    #     x_coords = coords[:, 0].numpy()\n",
        "    #     y_coords = coords[:, 1].numpy()\n",
        "\n",
        "    #     # Normalize coordinates to start from (0,0)\n",
        "    #     min_x, max_x = int(np.min(x_coords)), int(np.max(x_coords))\n",
        "    #     min_y, max_y = int(np.min(y_coords)), int(np.max(y_coords))\n",
        "    #     norm_x = x_coords - min_x\n",
        "    #     norm_y = y_coords - min_y\n",
        "\n",
        "    #     width = int(max_x - min_x + 1)\n",
        "    #     height = int(max_y - min_y + 1)\n",
        "\n",
        "    #     # Create a grid mapping from (x, y) to embedding index\n",
        "    #     grid = {}\n",
        "    #     for idx, (x, y) in enumerate(zip(norm_x, norm_y)):\n",
        "    #         grid[(x, y)] = idx\n",
        "\n",
        "    #     # Generate spiral order coordinates\n",
        "    #     spiral_coords = self.generate_spiral_coords(width, height)\n",
        "\n",
        "    #     # Collect tile embeddings in spiral order\n",
        "    #     spiral_order = []\n",
        "    #     sorted_coords = []\n",
        "    #     for coord in spiral_coords:\n",
        "    #         idx = grid.get(coord)\n",
        "    #         if idx is not None:\n",
        "    #             spiral_order.append(tile_embeds[idx])\n",
        "    #             sorted_coords.append((coord[0] + min_x, coord[1] + min_y))  # Convert back to original coordinates\n",
        "\n",
        "    #     # Convert list to tensor\n",
        "    #     if len(spiral_order) == 0:\n",
        "    #         print(\"!----- Spiral list is empty\")\n",
        "    #         return torch.zeros(0, self.embed_dim)\n",
        "\n",
        "    #     spiral_embeds = torch.stack(spiral_order)  # [num_tiles, EMBED_DIM]\n",
        "\n",
        "    #     # VISUALIZATION: Plot Spiral Traversal Inline\n",
        "    #     plt.figure(figsize=(8, 8))\n",
        "    #     sorted_coords = np.array(sorted_coords)  # Convert list to NumPy array\n",
        "\n",
        "    #     plt.scatter(coords[:, 0], coords[:, 1], c=\"blue\", alpha=0.5, label=\"Original Tiles\")\n",
        "    #     plt.plot(sorted_coords[:, 0], sorted_coords[:, 1], color=\"red\", linewidth=1.5, linestyle=\"dashed\", label=\"Spiral Path\")\n",
        "    #     plt.scatter(sorted_coords[:, 0], sorted_coords[:, 1], c=\"red\", label=\"Spiral Tiles\")\n",
        "\n",
        "    #     for i, (x, y) in enumerate(sorted_coords[:10]):  # Label first 10 tiles\n",
        "    #         plt.text(x, y, str(i), fontsize=10, color=\"black\")\n",
        "\n",
        "    #     plt.xlabel(\"X Coordinate\")\n",
        "    #     plt.ylabel(\"Y Coordinate\")\n",
        "    #     plt.title(\"Spiral Traversal of Tiles\")\n",
        "    #     plt.gca().invert_yaxis()  # Flip y-axis to match image coordinates\n",
        "    #     plt.legend()\n",
        "    #     plt.grid(True)\n",
        "    #     plt.show()\n",
        "\n",
        "    #     return spiral_embeds  # No need to return coordinates since they are visualized\n",
        "# #####################################################\n",
        "#        # END METHOD WITH VISUALIZER FOR SPIRAL ORDER\n",
        "# #####################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6A8cxtpJI-R"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "####################################\n",
        "####  EMBEDDING VISUALIZER  ########\n",
        "####################################\n",
        "def visualize_embeddings(dataloader, model, num_samples=500):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (tile_embeds, label) in enumerate(dataloader):\n",
        "            if i * tile_embeds.shape[0] > num_samples:\n",
        "                break  # Limit to `num_samples`\n",
        "\n",
        "            tile_embeds = tile_embeds.to(device)\n",
        "            logits = model(tile_embeds)  # Get model outputs\n",
        "\n",
        "            embeddings.append(logits.cpu().numpy())  # Store embeddings\n",
        "            labels.append(label.cpu().numpy())\n",
        "\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    labels = np.hstack(labels)\n",
        "\n",
        "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "    embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap=\"viridis\", alpha=0.7)\n",
        "    plt.colorbar()\n",
        "    plt.title(\"t-SNE Visualization of Embeddings\")\n",
        "    plt.xlabel(\"t-SNE Component 1\")\n",
        "    plt.ylabel(\"t-SNE Component 2\")\n",
        "    plt.savefig(os.path.join(PLOTS_DIR, 'embedding_tsne.png'))\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "visualize_embeddings(test_loader, model)\n",
        "\n",
        "#######################################\n",
        "####  EMBEDDING VISUALIZER END ########\n",
        "#######################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OjC4q4smso5"
      },
      "outputs": [],
      "source": [
        "%reset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
